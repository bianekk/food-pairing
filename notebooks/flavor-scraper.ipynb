{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FlavorDB Scraper\n",
    "____\n",
    "\n",
    "[Source](https://vchoo.github.io)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for basic data science\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# for downloading files off the internet\n",
    "import urllib.request\n",
    "import json\n",
    "import time\n",
    "\n",
    "\n",
    "# for network graphs\n",
    "from colour import Color\n",
    "from matplotlib.collections import LineCollection\n",
    "import networkx as nx\n",
    "import mpld3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON files are at addresses of this form\n",
    "def flavordb_entity_url(x):\n",
    "    return \"https://cosylab.iiitd.edu.in/flavordb/entities_json?id=\"+str(x)\n",
    "\n",
    "\n",
    "# translates the JSON file at the specified web address into a dictionary\n",
    "def get_flavordb_entity(x):\n",
    "    # source: https://stackoverflow.com/questions/12965203/how-to-get-json-from-webpage-into-python-script\n",
    "    with urllib.request.urlopen(flavordb_entity_url(x)) as url:\n",
    "        return json.loads(url.read().decode())\n",
    "    return None\n",
    "\n",
    "# the names of the \"columns\" in the raw JSON objects\n",
    "def flavordb_entity_cols():\n",
    "    return [\n",
    "        'entity_id', 'entity_alias_readable', 'entity_alias_synonyms',\n",
    "        'natural_source_name', 'category_readable', 'molecules'\n",
    "    ]\n",
    "\n",
    "# what we want to rename the JSON object \"columns\" to\n",
    "def flavordb_df_cols():\n",
    "    return [\n",
    "        'entity id', 'alias', 'synonyms',\n",
    "        'scientific name', 'category', 'molecules'\n",
    "    ]\n",
    "\n",
    "# \"subcolumns\" in the \"molecules\" column that we are interested in\n",
    "def molecules_df_cols():\n",
    "    return ['pubchem id', 'common name', 'flavor profile']   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_flavordb_dataframes(flavor_df, molecules_df):\n",
    "    \"\"\"\n",
    "    Helps ensure consistent intra-column typing and converts all strings to lowercase.\n",
    "    \"\"\"\n",
    "    strtype = type('')\n",
    "    settype = type(set())\n",
    "    \n",
    "    # ensuring that these columns have type str\n",
    "    for k in ['alias', 'scientific name', 'category']:\n",
    "        flavor_df[k] = [\n",
    "            elem.strip().lower() if isinstance(elem, strtype) else ''\n",
    "            for elem in flavor_df[k]\n",
    "        ]\n",
    "    \n",
    "    # ensuring that these columns are always a set of str\n",
    "    def map_to_synonyms_set(elem):\n",
    "        if isinstance(elem, settype):\n",
    "            return elem\n",
    "        elif isinstance(elem, strtype):\n",
    "            if len(elem) == 0:\n",
    "                return \" \"\n",
    "            # if it's a string of a set,\n",
    "            elif elem[0] == '{' and elem[-1] == '}':\n",
    "                # convert it to a set\n",
    "                return eval(elem)\n",
    "            else:\n",
    "                # else it's probably directly from source\n",
    "                return set(elem.strip().lower().split(', '))\n",
    "        else:\n",
    "            return set()\n",
    "    \n",
    "    flavor_df['synonyms'] = [\n",
    "        map_to_synonyms_set(elem)\n",
    "        for elem in flavor_df['synonyms']\n",
    "    ]\n",
    "    \n",
    "    molecules_df['flavor profile'] = [\n",
    "        set([x.strip().lower() for x in elem])\n",
    "        for elem in molecules_df['flavor profile']\n",
    "    ]\n",
    "    \n",
    "    return [\n",
    "        flavor_df.groupby('entity id').first().reset_index(),\n",
    "        molecules_df.groupby('pubchem id').first().reset_index()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate dataframes from some of the JSON objects\n",
    "def get_flavordb_dataframes(start, end):\n",
    "    \"\"\"\n",
    "    Download JSON data, converts it to DataFrames, and cleans them.\n",
    "    \n",
    "    Returns DataFrames for both foods and molecules, as well as missing JSON entries.\n",
    "    \"\"\"\n",
    "    # make intermediate values to make dataframes from\n",
    "    flavordb_data = []\n",
    "    molecules_dict = {}\n",
    "    missing = [] # numbers of the missing JSON files during iteration\n",
    "    \n",
    "    flavordb_cols = flavordb_entity_cols()\n",
    "    \n",
    "    for i in range(start, end):\n",
    "        # we use a try-except here because some of the JSON pages are missing\n",
    "        try:\n",
    "            # 1: Find the JSON file. Gets the ith food entity, as a JSON dict\n",
    "            fdbe = get_flavordb_entity(i + 1)\n",
    "\n",
    "            # get only the relevant fields (columns) of the dict\n",
    "            flavordb_series = [fdbe[k] for k in flavordb_cols[:-1]]\n",
    "            flavordb_series.append( # convert the field to a set\n",
    "                set([m['pubchem_id'] for m in fdbe['molecules']])\n",
    "            )\n",
    "            flavordb_data.append(flavordb_series)\n",
    "\n",
    "            # update the molecules dataframe with the data in 'molecules' field\n",
    "            for m in fdbe['molecules']:\n",
    "                if m['pubchem_id'] not in molecules_dict:\n",
    "                    molecules_dict[m['pubchem_id']] = [\n",
    "                        m['common_name'],\n",
    "                        set(m['flavor_profile'].split('@'))\n",
    "                    ]\n",
    "        except urllib.error.HTTPError as e:\n",
    "            if e.code == 404: # if the JSON file is missing\n",
    "                missing.append(i)\n",
    "            else:\n",
    "                raise RuntimeError(\n",
    "                    'Error while fetching JSON object from ' + flavordb_entity_url(x)\n",
    "                ) from e\n",
    "            \n",
    "    # generate the dataframes\n",
    "    flavordb_df = pd.DataFrame(\n",
    "        flavordb_data,\n",
    "        columns=flavordb_df_cols()\n",
    "    )\n",
    "    molecules_df = pd.DataFrame(\n",
    "        [\n",
    "            [k, v[0], v[1]]\n",
    "             for k, v in molecules_dict.items()\n",
    "        ],\n",
    "        columns=molecules_df_cols()\n",
    "    )\n",
    "    \n",
    "    # clean up the dataframe columns\n",
    "    flavordb_df, molecules_df = clean_flavordb_dataframes(flavordb_df, molecules_df)\n",
    "    \n",
    "    return [flavordb_df, molecules_df, missing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_flavordb_dataframes(df0, df1, ranges):\n",
    "    \"\"\"\n",
    "    Adds more data to the specified DataFrames, and saves them as CSV files.\n",
    "    \n",
    "    If successful, returns the specified DataFrames, now updated, and any missing JSON files.\n",
    "    \"\"\"\n",
    "    df0_old = df0\n",
    "    df1_old = df1\n",
    "    missing_old = []\n",
    "\n",
    "    # time how long it took to download the files\n",
    "    start = time.time()\n",
    "    \n",
    "    # for each range in ranges, save your progress.\n",
    "    # don't continue with the program unless everything succeeds!\n",
    "    try:\n",
    "        for a, b in ranges:\n",
    "            df0_new, df1_new, missing_new = get_flavordb_dataframes(a, b)\n",
    "            \n",
    "            # df0_old = df0_old.append(df0_new, ignore_index=True)\n",
    "            df0_old = pd.concat([df0_old, df0_new], ignore_index=True)\n",
    "            # df1_old = df1_old.append(df1_new, ignore_index=True)\n",
    "            df1_old = pd.concat([df1_old, df1_new], ignore_index=True)\n",
    "            missing_old.extend(missing_new)\n",
    "        \n",
    "        return df0_old, df1_old, missing_old\n",
    "    except:\n",
    "        raise # always throw the error so you know what happened\n",
    "    finally:\n",
    "        # even if you throw an error, you'll have saved them as csv files\n",
    "        df0_old.to_csv('flavordb.csv')\n",
    "        df1_old.to_csv('molecules.csv')\n",
    "\n",
    "        end = time.time()\n",
    "        mins = (end - start) / 60.0\n",
    "        print('Downloading took: '+ str(mins) + ' minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take new dataframes\n",
    "df0 = pd.DataFrame(columns=flavordb_df_cols())\n",
    "df1 = pd.DataFrame(columns=molecules_df_cols())\n",
    "\n",
    "# fill the DataFrames with JSON files up to id = 1000\n",
    "ranges = [(50 * i, 50 * (i + 1)) for i in range(20)]\n",
    "# update & save the dataframes as csv files\n",
    "update_flavordb_dataframes(df0, df1, ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the missing entries\n",
    "def missing_entity_ids(flavor_df):\n",
    "    \"\"\"\n",
    "    Get the IDs of the missing JSON entries for this particular food DataFrame.\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    entity_id_set = set(flavor_df['entity id'])\n",
    "    for i in range(1, 1 + max(entity_id_set)):\n",
    "        if i not in entity_id_set:\n",
    "            out.append(i)\n",
    "    return out\n",
    "\n",
    "\n",
    "# loads the dataframes from csv files\n",
    "def load_db():\n",
    "    settype = type(set())\n",
    "    \n",
    "    df0 = pd.read_csv('flavordb.csv')[flavordb_df_cols()]\n",
    "    df0['synonyms'] = [eval(x) if isinstance(x, settype) else x for x in df0['synonyms']]\n",
    "    df0['molecules'] = [eval(x) for x in df0['molecules']]\n",
    "    \n",
    "    df1 = pd.read_csv('molecules.csv')[molecules_df_cols()]\n",
    "    df1['flavor profile'] = [eval(x) for x in df1['flavor profile']]\n",
    "    \n",
    "    df0, df1 = clean_flavordb_dataframes(df0, df1)\n",
    "    return df0, df1, missing_entity_ids(df0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing_ids = the missing ids that are less than the max one found\n",
    "flavor_df, molecules_df, missing_ids = load_db()\n",
    "flavor_df.to_csv('flavordb.csv')\n",
    "molecules_df.to_csv('molecules.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
